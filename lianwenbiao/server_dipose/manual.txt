建议直接点击观看 http://note.youdao.com/noteshare?id=0cccf748c817e895199c7d09d19eb3bf&sub=A087DA33314544E9ACCEF8057CD3A3A7



注：执行指令时需留意自身有无一定权限。如过滤字符时需要创建文件保存结果的，则需要注意自身在指定目录下是否有写权限(机器权限管理不一致，需要特别留意)
有些不完善的地方需要使用者手动处理。若觉得实在不方便可联系另外写脚本补上

目前文件在服务器上的存放 ―― 主路径：path -> /home/lijunjie/lw/
数据 path/data   代码 path/code   工具 path/tool(如TreeTagger)

建议代码在服务器上运行时，先在 165 的机器上先试跑。该机器上的 /home/lijunjie/lw/ 有相同的环境，path/data 中也存有 8 支股票的数据作为Demo

0、在各机器上执行创建目录等指令
    1) cmd.sh  
       直接 bash cmd.sh，然后输入需要在各机器上的指令，如 mkdir /home/lijunjie/lw
       注：A、要用 bash 而非 sh 去执行该文件
            B、每次只能输入一条指令
    2）su-cmd.sh
       需要su权限时使用。用法同上。
       注：A、相应的用户和密码皆写死。若对应机器中，用户与密码不一致，则无法正常操作
    2）concurrent-cmd.sh
       以 su 的身份，在各服务器上同时执行指令(通常是直接调用 python 文件处理数据用)
       输入样例 ―― 
        python /home/lijunjie/lw/code/char_filter.py /home/lijunjie/lw/data/tmp_txt/ /home/lijunjie/lw/data/
       注：若路径中存在空格，需自己在输入命令时自己手动转义

1、从本地传输数据/代码文件到10台服务器上
    1) post_data.py
       解析得到必要中止条件后，自身会再调用 post_data.sh 进行传输工作
        输入参数：本地文件路径  服务器上文件路径(先通过 cmd.sh 创建)，如：
        python post_data.py /home/luowang/financial_reports_data/attach /home/lijunjie/lw/data
        注：A、目前年报数据统一存放在了 /home/lijunjie/lw/data/ 下
            B、该文件通过待传输的最后一个文件名和大小来确认传输完成并返回信息，因此万一该名字相同且大小相同的文件有多个，则会提前终止。因此需要手动进行一些文件调整
               a、查看最后一个文件的名字及其大小
                  打开 post_data.py 文件，在"print last_file_size"下面输入 "raw_input()"  => 运行 post_data.py 并在中止时记录文件名和大小 => ctrl C 终止程序 => 删去"raw_input()" 
               b、查看待传送文件夹下有几个这样名字的文件
                  在待传输的文件夹下搜寻有几个相同的文件，最好能再次确认大小来确保是同个文件。相应指令如下，文件数为输出的最左边数字
                  find dir -name "file_name" | wc
               c、若有多个，则需做出相应调整
                  如共有 n 个该文件，则打开 post_data.sh 并将 expect "$3" 在相同位置复制 n - 1 次
            C、传输过程中存在内容丢失问题。实测 220MB 的文件夹，会丢失 0 - 100 Byte 不等
            D、假定了传输文件中的单个文件，大小不会超过8MB，可能存在隐患
            E、权限会是一个很大的干扰项。如果要传输文件到(或文件来源在) /usr/lib/ 这种地方的，需要极高的权限，则要另外进行处理。目前没给出对应文件，还是本人自己手动编写，实在又需要再加上
    2) post_data.sh
        利用 scp 和 expect 进行传输工作，需要三个参数：本地文件路径(path_from)、服务器上的文件路径(path_to)、终止反馈
        其中终止反馈由post_data.py解析得，因而此文件不建议直接调用
2、传输指令进行处理
    1) adapt-process.py
       A、根据待处理文件夹中下一层子文件的大小以及机器数，给每个机器分配不同的处理对象
        B、调用 py-cmd.py 将传输指令包装并传送至各机器上执行
        C、完成后调用 get_data.py 从服务器的指定路径中获取结果文件，传至 "临时文件夹/tmpx" 中，其中 x 代表机器编号 ( 0-8，其中 172.31.238.129 不可用，已被剔除 ) (可选)
        D、将临时文件夹中的内容合并至指定文件夹中，并删除临时文件夹中的文件    (可选)
        
        输入参数：执行指令 处理对象 结果文件 本地临时文件夹 本地存放结果文件夹，如：
        python process.py "ls" .. /home/lijunjie ./tmp ./test/  ==>
        在服务器的 .. 文件夹下调用 ls，然后将各服务器上 /home/lijunjie 下的内容作为结果，传至本地的 ./tmp 中，然后合并至 ./test 中 
        任务分配的方式相对固定，因此如果运行过程中有一台服务器崩溃，则要重新运行文件。可以通过自己写心跳包捕获异常，动态调整分配，但目前还没做
        
        注：A、指令需用双引号包着，若有 -s 这样的参数也包括进去；但不可包含处理对象文件
            B、处理对象文件为服务器上的文件，且每次只能处理一个(可以是文件夹)
            C、后面的三个参数为可选，即仅进行处理但不需要返回结果数据文件时可以不写(事实上目前也不建议使用，因为脚本功能太分散了，用了易引起混乱。以后脚本合并完整后可能用得上)
            D、注意后面三个参数的路径，都是文件夹，但只有最后一个在结尾需要 斜杠
            E、上面例子，处理对象的写法其实不合适。处理对象应尽可能用绝对路径(非强制)，且由于文件分配的关系，应确保本地与服务器上的处理对象路径及里面的文件内容都要一致(强制)
            F、当可用的服务器数发生改变时，需进入代码中修改 machine_num 数值
        pdf转txt：8个stock单机处理(165) ―― 除去00005(特大)，每个平均 3 分钟(可能资源不对等)
                  8台服务器处理 ―― 每台处理 245 个，每个平均 1.5 分钟
    2) process.py
       使用存在缺陷，不建议使用 (主要是这种分配方式不便于后续管理)
       与 adapt-process.py 中给不同机器分配任务的算法不同。设现有服务器数量 N 则
        上面的文件操作为：直接将下一层文件夹划为 N 等份
        此文件操作为：将下一层文件夹根据文件大小，尽可能划为相等的 N 等份
    3) py-cmd.py
       用于对执行指令进行包装，以正确传输(此处设定任何操作都以 root 身份执行)
        注：A、为确保正确返回，最好在自己的代码文件完成操作后返回固定的信息(如"DONE")，并在此文件的最后一个 expect 处的内容，改成该信息

3、获取结果返回本地
    1) get_data.sh(现放弃使用)  
              输入参数：服务器上文件路径(path_from)  本地文件路径(path_to)  获取数据的来源(服务器编号i)  执行指令
     2) po_test/ 中的 post_data.py 与 post_data.sh
         需布置到服务器上，目前需固定在 /home/lijunjie/ 下。当需要返回结果文件时，则会通过 adapt-process.py (或通过 cmd.sh 手动输入指令)调用此文件
         输入参数：服务器上文件路径path_from  本地文件路径(path_to)  本地用户名(username)  本地ip(userip)  本地用户(password)
         注：A、留意本地用户有无所需权限