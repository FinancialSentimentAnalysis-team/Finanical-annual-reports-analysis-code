{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/yyy/wk5/txt_wighted/00900_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/02388_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00688_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01109_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00683_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00966_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00821_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00925_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00373_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00388_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00071_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00626_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00075_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00459_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00218_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00812_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00662_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00014_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00335_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00194_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00016_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00017_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00111_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00012_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00010_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00011_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00034_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00258_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00050_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00510_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00056_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01124_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00054_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00123_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00878_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00211_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00978_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01224_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00952_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00369_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00655_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01111_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01200_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00363_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00188_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00173_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00754_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00488_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00088_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00588_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00604_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00086_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00081_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00440_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00083_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00613_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00023_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00127_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00020_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00247_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00026_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/01098_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00041_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00480_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00253_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00101_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00227_words_weights.xls saved successfully.\n",
      "/usr/yyy/wk5/txt_wighted/00165_words_weights.xls saved successfully.\n",
      "-------------Done------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xlwt\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_stock_dir(root_path):\n",
    "    '''\n",
    "    functionality: reads a txt file and returns a dict of file names\n",
    "    \n",
    "    input: a file path in txt_tagged_init directory\n",
    "    \n",
    "    return: a dict\n",
    "            The keys are stock names. The values are a list of file paths that belong to the stock\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result_a = defaultdict(list)\n",
    "    result_i = defaultdict(list)\n",
    "    \n",
    "    for file_name in os.listdir(root_path):\n",
    "        if \"_Annual_\" in file_name:\n",
    "            result_a[file_name[:5]].append(root_path + file_name)\n",
    "        else:\n",
    "            result_i[file_name[:5]].append(root_path + file_name)\n",
    "    \n",
    "    _sort_dict(result_a)\n",
    "    _sort_dict(result_i)\n",
    "    result = _concat_dicts(result_a, result_i)\n",
    "    return result\n",
    "\n",
    "def _sort_dict(d):\n",
    "    '''\n",
    "    functionality: assuming the values of the dict are lists, sorts the values\n",
    "    \n",
    "    input: a dict that has stock names as keys and lists of file paths as values\n",
    "    \n",
    "    return: None\n",
    "    '''\n",
    "    \n",
    "    for k in d:\n",
    "        d[k] = sorted(d[k])\n",
    "\n",
    "def _concat_dicts(d1, d2):\n",
    "    '''\n",
    "    functionality: assuming the values of the dicts are lists, combines these two dicts into one dict\n",
    "    \n",
    "    input: a dict representing annual that has stock names as keys and lists of file paths as values\n",
    "           a dict representing interim that has stock names as keys and lists of file paths as values\n",
    "    \n",
    "    return: a combined dict with the same format as the input dicts.\n",
    "    '''\n",
    "    \n",
    "    result = defaultdict(list)\n",
    "    for k in d1:\n",
    "        result[k] = d1[k] + d2[k]\n",
    "    return result\n",
    "\n",
    "def get_txt_dir(stock_dir):\n",
    "    '''\n",
    "    functionality: returns the text string in each file\n",
    "    \n",
    "    input: a dict obtained from get_stock_dir(root_path)\n",
    "    \n",
    "    return: a dict\n",
    "            The keys are stock names. The values are lists of text strings; each position of the \n",
    "            text string matches the position of the file name in stock_dir[stock_name]\n",
    "    '''\n",
    "    \n",
    "    result = defaultdict(list)\n",
    "    for stock_name in stock_dir:\n",
    "        for file_name in stock_dir[stock_name]:\n",
    "            open_file = open(file_name, 'r')\n",
    "            content = open_file.readlines()\n",
    "            open_file.close()\n",
    "            if len(content) == 0:\n",
    "                content = ''\n",
    "            else:\n",
    "                content = content[0]\n",
    "            result[stock_name].append(content)\n",
    "    return result\n",
    "\n",
    "def get_TFIDF(root_path):\n",
    "    '''\n",
    "    functionality: calculates the TF-IDF of the data. The domain is all the files for annual and for interim\n",
    "    \n",
    "    input: a file path in txt_tagged_init directory\n",
    "    \n",
    "    return: a dict\n",
    "            The keys are stock names. The values are a list of three element.\n",
    "                list[0] is a dict for annual\n",
    "                    In this dict, keys are years and values are sub-dict\n",
    "                        In this sub-dict, keys are words and values are the weights corresponding to the words\n",
    "                list[1] is a dict for interim\n",
    "                    In this dict, keys are years and values are sub-dict\n",
    "                        In this sub-dict, keys are words and values are the weights corresponding to the words\n",
    "                list[2] is a list of words\n",
    "\n",
    "    '''\n",
    "\n",
    "    stock_dir = get_stock_dir(root_path)\n",
    "    txt_dir = get_txt_dir(stock_dir)\n",
    "    # stock_dir: key = stock_name, value = list of file_name    \n",
    "    # txt_dir  : key = stock_name, value = list of txt_str\n",
    "\n",
    "    stock_names = sorted(stock_dir.keys())\n",
    "    \n",
    "    full_txt_list = [] \n",
    "    for stock_name in stock_names:\n",
    "        for txt_str in txt_dir[stock_name]:\n",
    "            full_txt_list.append(txt_str)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    transformer = TfidfTransformer()        \n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(full_txt_list))            \n",
    "    weights = tfidf.toarray() # list of sub-lists, each sub-list is the weight of a word\n",
    "    words = vectorizer.get_feature_names()            \n",
    "\n",
    "    txt_freq_dict = dict()\n",
    "    \n",
    "    for txt_index in range(len(full_txt_list)):\n",
    "        if any(weights[txt_index]):\n",
    "            txt_freq_dict[full_txt_list[txt_index]] = weights[txt_index]\n",
    "    \n",
    "    file_freq_dict = dict()\n",
    "    \n",
    "    for stock_name in stock_names:\n",
    "        stock_file_list = stock_dir[stock_name]\n",
    "        stock_txt_list = txt_dir[stock_name]\n",
    "        for i in range(len(stock_txt_list)):\n",
    "            if stock_txt_list[i] in txt_freq_dict.keys():\n",
    "                file_freq_dict[stock_file_list[i].split('/')[-1]] = txt_freq_dict[stock_txt_list[i]]\n",
    "\n",
    "    result = dict()\n",
    "    \n",
    "    for stock_name in stock_names:\n",
    "        l = [defaultdict(dict), defaultdict(dict)] # l[0] is annual, l[1] is interim\n",
    "        l.append(words)\n",
    "        \n",
    "        for stock_file in file_freq_dict:\n",
    "            if stock_name in stock_file:\n",
    "                stock_info = stock_file.split('_')[:3] # returns [stock_name, year, term]\n",
    "                _modify_dict(l[0], words, stock_info, file_freq_dict[stock_file], 'Annual')\n",
    "                _modify_dict(l[1], words, stock_info, file_freq_dict[stock_file], 'Interim')\n",
    "                \n",
    "        result[stock_name] = l\n",
    "    return result\n",
    "\n",
    "def _modify_dict(result_dict, words, stock_info, freq_list, term):\n",
    "    '''\n",
    "    functionality: modifies the result_dict such that the keys will be years and the values will be dicts of words with weights\n",
    "    \n",
    "    input: a dict\n",
    "           a list of words\n",
    "           a list of information with the format : [stock_name, year, term]\n",
    "           the term is either 'Annual' or 'Interim'\n",
    "    \n",
    "    return: None\n",
    "    '''\n",
    "    \n",
    "    if term == stock_info[2]:\n",
    "        words_dict = dict()\n",
    "        for word_index in range(len(words)):\n",
    "            words_dict[words[word_index]] = freq_list[word_index]\n",
    "        result_dict[stock_info[1]] = words_dict\n",
    "\n",
    "def save_into_excel(result_path, data):\n",
    "    '''\n",
    "    functionality: saves the data into the destination result path\n",
    "    \n",
    "    input: a dict obtained from get_TFIDF(root_path)\n",
    "    \n",
    "    return: None\n",
    "    '''\n",
    "    \n",
    "    for stock_name in data:\n",
    "        result_file_path =  result_path + stock_name + '_words_weights.xls'\n",
    "        workbook = xlwt.Workbook()\n",
    "        words = data[stock_name][2]        \n",
    "        Annual_Sheet  = workbook.add_sheet('Annual')\n",
    "        Interim_Sheet = workbook.add_sheet('Interim')\n",
    "        \n",
    "        _write_sheet(Annual_Sheet,  words, data[stock_name][0])\n",
    "        _write_sheet(Interim_Sheet, words, data[stock_name][1])\n",
    "        \n",
    "        workbook.save(result_file_path)\n",
    "        print result_file_path, 'saved successfully.'\n",
    "\n",
    "def _write_sheet(sheet, words, datum):\n",
    "    '''\n",
    "    functionality: stores all the information in the data to the sheet\n",
    "    \n",
    "    input: the sheet in which you want to write\n",
    "           a list of words\n",
    "           a dict with the keys wof years and the values of dicts of words with weights\n",
    "    \n",
    "    return: None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col = 0\n",
    "    for year in sorted(datum):\n",
    "        sheet.write(0,col,'word')\n",
    "        sheet.write(0,col+1, year)\n",
    "        row = 1\n",
    "        sorted_list = sorted(datum[year].items(), key = (lambda x: x[1]), reverse = True)\n",
    "        \n",
    "        for word, weight in sorted_list:\n",
    "            if weight != 0:\n",
    "                sheet.write(row, col, word)\n",
    "                sheet.write(row, col+1, weight)\n",
    "                row += 1\n",
    "        col += 2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root_path = '/usr/yyy/wk5/txt_tagged_init/'\n",
    "    result_path = '/usr/yyy/wk5/excel_weighted/'\n",
    "    \n",
    "    if not os.path.exists(result_path):\n",
    "        os.mkdir(result_path)\n",
    "    \n",
    "    data = get_TFIDF(root_path)\n",
    "    \n",
    "    save_into_excel(result_path, data)\n",
    "\n",
    "    print '-------------Done------------'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
