{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/yyy/wk5/Count/SentiWordSet/00227_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00604_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00900_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/02388_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00127_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00688_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00335_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00683_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00966_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00821_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00925_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00373_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00510_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00071_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00626_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00075_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00459_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00218_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00188_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00662_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00111_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01109_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00194_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00016_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00017_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00014_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00012_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00010_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00011_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00034_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00258_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00173_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01200_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01124_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00054_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00123_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00878_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00613_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00211_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00978_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01224_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00952_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00369_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00655_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00363_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00812_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00050_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00754_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00088_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00588_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00056_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00086_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00081_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00440_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00083_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01111_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00023_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00488_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00020_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00247_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00026_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/01098_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00041_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00480_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00253_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00101_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00388_SentiWordSet_count.xls completed\n",
      "\n",
      "/usr/yyy/wk5/Count/SentiWordSet/00165_SentiWordSet_count.xls completed\n",
      "\n",
      "------------Done-------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xlwt\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_dictionary_for_SentiWordSet(dictionary_path):\n",
    "    '''\n",
    "    functionality: reads the SentiWordNet Dictionary\n",
    "    \n",
    "    input: the path of the dictioary\n",
    "    \n",
    "    return: a tuple of two dicts (you can call them postive_dictionary and negative_dictionary)\n",
    "            Each dict has words as dict, tuple of (positive score, negative score) as values.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    csv_file = open(dictionary_path, 'r')\n",
    "    reader = csv.reader(csv_file)\n",
    "    for line in reader:\n",
    "        if line[0] != 'POS':\n",
    "            for word in line[4].split(','):\n",
    "                d[word[:-2]].append((word.split('#')[0] + '#' + line[0], line[2], line[3]))\n",
    "    csv_file.close()\n",
    "    pos_result_dict = dict()\n",
    "    neg_result_dict = dict()\n",
    "    for word in d:\n",
    "        dic = dict()        \n",
    "        _property = set(word_info[0] for word_info in d[word])\n",
    "        for word_with_property in _property:\n",
    "            dic[word_with_property] = [0,0]\n",
    "        for word_with_property in _property:\n",
    "            count = 0\n",
    "            for word_info in d[word]:\n",
    "                if word_info[0] == word_with_property:\n",
    "                    count += 1\n",
    "                    dic[word_with_property][0] += float(word_info[1])\n",
    "                    dic[word_with_property][1] += float(word_info[2])\n",
    "            dic[word_with_property][0] /= count\n",
    "            dic[word_with_property][1] /= count\n",
    "        for key, value in dic.items():\n",
    "            if value[0] != 0:\n",
    "                pos_result_dict[key.strip()] = value\n",
    "            if value[1] != 0:\n",
    "                neg_result_dict[key.strip()] = value\n",
    "    return pos_result_dict, neg_result_dict\n",
    "\n",
    "def Stocks_info_dict(root_path, pos_dictionary, neg_dictionary):\n",
    "    '''\n",
    "    functionality: given a tagged txt file, analyzes the file and stores the information into a dict\n",
    "    \n",
    "    input: the path of the tagged txt file\n",
    "           the positive dictionary obtained from read_dictionary_for_SentiWordNet(dictionary_path)\n",
    "           the negative dictionary obtained from read_dictionary_for_SentiWordNet(dictionary_path)\n",
    "    \n",
    "    return: a dict\n",
    "            The keys are the names of stocks, the values are a list of two dicts.\n",
    "            Each sub-dict is either for annual or for interim.\n",
    "            Each key in a sub-dict is the year, each value in a sub-dict is also a dict. Detail in _analyze_txt_str(txt_str, pos_dictionary, neg_dictionary)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    stock_dict = dict()\n",
    "    for stock_name in set(file_name[:5] for file_name in os.listdir(root_path)):\n",
    "        year_dict_a = defaultdict(dict) # make sure every time checks if the year exists\n",
    "        year_dict_i = defaultdict(dict) # make sure every time checks if the year exists\n",
    "        \n",
    "        for file_name in sorted(os.listdir(root_path)):\n",
    "            if file_name[:5] == stock_name:\n",
    "                year = file_name[6:10]\n",
    "                if file_name.split('_')[2] == 'Annual':\n",
    "                    year_dict_a[year] = _analyze_txt_str(_extract_txt(root_path + file_name), pos_dictionary, neg_dictionary)\n",
    "                else:\n",
    "                    year_dict_i[year] = _analyze_txt_str(_extract_txt(root_path + file_name), pos_dictionary, neg_dictionary)\n",
    "        stock_dict[stock_name] = [year_dict_a, year_dict_i]\n",
    "    return stock_dict\n",
    "\n",
    "def _analyze_txt_str(txt_str, pos_dictionary, neg_dictionary):\n",
    "    '''\n",
    "    functionality: returns a dict of information\n",
    "    \n",
    "    input: a str of txt\n",
    "           the positive dictionary obtained from read_dictionary_for_SentiWordNet(dictionary_path)\n",
    "           the negative dictionary obtained from read_dictionary_for_SentiWordNet(dictionary_path)    \n",
    "    \n",
    "    return: a dict\n",
    "            There are two keys in the dict: 'positive', 'negative'.\n",
    "            The values are sub-dict.\n",
    "            Each sub-dict has words as keys and frequencies as values\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    word_dict = defaultdict(int)\n",
    "    for word in txt_str.split():\n",
    "        word_dict[word] += 1\n",
    "    pos_result_dict = dict()\n",
    "    neg_result_dict = dict()\n",
    "    for word in pos_dictionary:\n",
    "        pos_result_dict[word] = word_dict[word]\n",
    "    for word in neg_dictionary:\n",
    "        neg_result_dict[word] = word_dict[word]\n",
    "    result_dict = dict()\n",
    "    result_dict['positive'] = pos_result_dict\n",
    "    result_dict['negative'] = neg_result_dict\n",
    "    return result_dict\n",
    "\n",
    "# returns the string of the file\n",
    "def _extract_txt(file_path):\n",
    "    '''\n",
    "    functionality: returns a str of text in the txt file\n",
    "    \n",
    "    input: the path of the tagged txt file\n",
    "    \n",
    "    return: str of text\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    o = open(file_path, 'r')\n",
    "    lines = o.readlines()\n",
    "    if len(lines) == 0:\n",
    "        return ''\n",
    "    result = ''\n",
    "    for word_property_init in lines[0].split():\n",
    "        new_word = _alter_word(word_property_init)\n",
    "        if new_word != '':\n",
    "            result += new_word + ' '\n",
    "    o.close()\n",
    "    return result\n",
    "\n",
    "def _alter_word(word_property_init):\n",
    "    '''\n",
    "    functionality: returns the word in a different format\n",
    "    \n",
    "    input: a tagged word\n",
    "    \n",
    "    return: a str having the word with its part-of-speech\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    word_info = word_property_init.split('_')\n",
    "    _property = word_info[1].upper()\n",
    "    if _property in ['JJ', 'JJS','JJR']:\n",
    "        return word_info[2].lower() + '#a'\n",
    "    elif _property in ['RB', 'RBR', 'RBS']:\n",
    "        return word_info[2].lower() + '#r'\n",
    "    elif _property in ['NN', 'NNS', 'NP', 'NPS']:\n",
    "        return word_info[2].lower() + '#n'\n",
    "    elif 'V' in _property:\n",
    "        return word_info[2].lower() + '#v'\n",
    "    return ''\n",
    "\n",
    "def save_into_excel(result_path, stock_dict):\n",
    "    '''\n",
    "    functionality: save the data into the result_path\n",
    "    \n",
    "    input: the destination where you want to store\n",
    "           the dict obtained from Stocks_info_dict(root_path, pos_dictionary, neg_dictionary)\n",
    "    \n",
    "    return: None\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    for stock_name in stock_dict:\n",
    "        workbook =  xlwt.Workbook()\n",
    "\n",
    "        _create_sheets(workbook, stock_dict[stock_name][0],  stock_name, 'Annual')\n",
    "        _create_sheets(workbook, stock_dict[stock_name][1],  stock_name, 'Interim')\n",
    "\n",
    "        workbook.save(result_path + stock_name + '_SentiWordSet_count.xls')\n",
    "        print result_path + stock_name + '_SentiWordSet_count.xls', 'completed\\n'\n",
    "\n",
    "def _create_sheets(workbook, data, stock_name, tag):\n",
    "    '''\n",
    "    functionality: creates an annual sheet and an interim sheet\n",
    "    \n",
    "    input: the workbook object\n",
    "           the dict: keys are years, values are sub-dicts.\n",
    "                     each sub-dict: keys are categories (you can also say determinants), values are sub-sub-dict\n",
    "                     each sub-sub-dict: keys are words, values are frequencies\n",
    "           tag is either 'Annual' or 'Interim'\n",
    "    \n",
    "    return: None\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    Positive = workbook.add_sheet('Positive_' + tag)\n",
    "    Negative = workbook.add_sheet('Negative_' + tag)    \n",
    "    \n",
    "    _write_sheets(Positive, data, tag.lower() + ' positive')\n",
    "    _write_sheets(Negative, data, tag.lower() + ' negative')\n",
    "\n",
    "\n",
    "def _write_sheets(sheet, data, tag):\n",
    "    '''\n",
    "    functionality: stores the data into the sheet\n",
    "    \n",
    "    input: the sheet you want to write in\n",
    "           the dict: keys are years, values are sub-dicts.\n",
    "                     each sub-dict: keys are categories (you can also say determinants), values are sub-sub-dict\n",
    "                     each sub-sub-dict: keys are words, values are frequencies\n",
    "           tag is either 'Annual' or 'Interim'\n",
    "    \n",
    "    return: None\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    sheet.write(0,0, tag)\n",
    "    determinant = tag.split()[1]\n",
    "    phrases = set()\n",
    "    col = 1\n",
    "    for year in sorted(data):\n",
    "        sheet.write(0,col, year)\n",
    "        for phrase in data[year][determinant]:\n",
    "            try:\n",
    "                phrases.add(unicode(phrase, 'utf-8'))\n",
    "            except:\n",
    "                pass\n",
    "        col += 1\n",
    "    phrases = sorted(phrases)\n",
    "\n",
    "    row = 1\n",
    "    for phrase in phrases:\n",
    "        sheet.write(row, 0, phrase)\n",
    "        col = 1\n",
    "        for year in sorted(data):\n",
    "            sheet.write(row, col, data[year][determinant][phrase])\n",
    "            col += 1        \n",
    "        row += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = '/usr/yyy/wk5/txt_tagged/'\n",
    "    result_path = '/usr/yyy/wk5/Count/SentiWordSet/'\n",
    "    dictionary_path = '/usr/yyy/dictionaries/SentiWordNet_filtered.csv'\n",
    "    \n",
    "    if not os.path.exists(result_path):\n",
    "        os.mkdir(result_path)\n",
    "        \n",
    "    pos_dictionary, neg_dictionary = read_dictionary_for_SentiWordSet(dictionary_path)\n",
    "    \n",
    "    stock_dict = Stocks_info_dict(root_path, pos_dictionary, neg_dictionary)\n",
    "    \n",
    "    save_into_excel(result_path, stock_dict)\n",
    "\n",
    "    print '------------Done-------------'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
